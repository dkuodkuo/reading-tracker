{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring Predictive Models\n",
    "\n",
    "Reading References:\n",
    "\n",
    "- http://blog.revolutionanalytics.com/2016/03/com_class_eval_metrics_r.html\n",
    "- http://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "## Performance Metrics\n",
    "\n",
    "|**Term**                   |**Definition**\n",
    "|--------------------------:|:-------------\n",
    "|**Confusion Matrix:**      |A contingency table of observations by their predicted vs actual class labels. For the notebook, assume the colums are the predicted labels and the rows are the actual labels.\n",
    "|**Accuracy:**              |The fraction of instances that are correctly classified. `sum(diagonal) / observations`\n",
    "|**Precision:**             |The fraction of correct predictions for a certain class. `diagonal / colsums`\n",
    "|**Recall:**                |The fraction of instances of a class that were correctly predicted. `diagonal / rowsums`\n",
    "|**F1:**                    |Harmonic mean (or a weighted average) of precision and recall. `2 * precision * recall / (precision + recall) `\n",
    "|**One-vs-all Matrices:**   |Confusion matrix for one class at a time. The sum of these matrices allows us to compute weighted metrics.\n",
    "|**Average Accuracy:**      |The fraction of correctly classified instances in the sum of one-vs-all matrices matrix.\n",
    "|**Macro-averaged Metrics:**|Average performance, equal weights by class.\n",
    "|**Micro-averaged Metrics:**|Average performance, weighted by sum of one-vs-all matrices. Favors classes with a larger number of instances.\n",
    "\n",
    "## Baseline Models\n",
    "\n",
    "|**Term**                   |**Definition**\n",
    "|--------------------------:|:-------------\n",
    "|**Majority-class Metrics:**|lol\n",
    "|**Random-guess Metrics:**  |lol\n",
    "|**Kappa Statistic:**       |lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data\n",
    "np.random.seed(0)\n",
    "data_classes = np.array(['a', 'b', 'c'])\n",
    "actual = np.random.choice(data_classes, size = 100, replace = True)\n",
    "\n",
    "predicted = actual.copy()\n",
    "mix_indices_actual = np.random.choice(range(100), size = 30, replace = False)\n",
    "mix_indices_predicted = np.random.choice(range(100), size = 30, replace = False)\n",
    "predicted[mix_indices_predicted] = actual[mix_indices_actual]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "References for further implementation:\n",
    "\n",
    "- https://stackoverflow.com/questions/2148543/how-to-write-a-confusion-matrix-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual a</th>\n",
       "      <th>actual b</th>\n",
       "      <th>actual c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predict a</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict b</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict c</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           actual a  actual b  actual c\n",
       "predict a        33         3         3\n",
       "predict b         3        29         2\n",
       "predict c         3         3        21"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manual implementation\n",
    "cm = np.zeros([3, 3]).astype(int)\n",
    "\n",
    "for cm_index_actual, i in enumerate(data_classes):\n",
    "    for cm_index_predict, j in enumerate(data_classes):\n",
    "        cm[cm_index_actual, cm_index_predict] = np.sum((actual == i) & (predicted == j))\n",
    "\n",
    "cm_index = ['predict ' + x for x in data_classes]\n",
    "cm_columns = \n",
    "pd.DataFrame(cm, index = predict_ind, columns = ['actual ' + x for x in data_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual a</th>\n",
       "      <th>actual b</th>\n",
       "      <th>actual c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>predict a</th>\n",
       "      <td>33</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict b</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>predict c</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           actual a  actual b  actual c\n",
       "predict a        33         3         3\n",
       "predict b         3        29         2\n",
       "predict c         3         3        21"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn implementation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(actual, predicted, labels = data_classes)\n",
    "\n",
    "pd.DataFrame(cm, index = ['predict ' + x for x in data_classes], columns = ['actual ' + x for x in data_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py37]",
   "language": "python",
   "name": "conda-env-py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
